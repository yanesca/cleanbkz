+ cjloss-t NTL-re átirni
+ az NTL beépitett GS -ével kiszámolni és kiiratni a GS-ét
+ az NTL beépitett BKZ-jével redukálni a cjlosst
+ egy dummy enumerationt irni és tesztelni (nyilván el fog hasalni a teszten) 
+ a doxygen-es doksikészitést tesztelni 
+ GPL- licencet a GNU conventionnek megfelelően hozzáadni és gitbe feltolni
+ kioperálni az NTL-es enumerationt (egy az egyben a schnor-euchnert adaptálja)
+ végrehajtani rajta a Phong féle optimalizálást - máshogyvolt szervezve ezért újraprogramoztam a pszeudokódjuk alapján
+ pruningot belerakni
+ lemérni a BKZ és az enumeration futási idejét - nem praktikus, mert BKZ-30 (amivel próbálkoztam) meg BKZ-35 (amit ők használtak) nagyon lassú és még magas dimenzióban is (65) megtalálja a legrövidebb vektort (nem hagy munkát az enumerationnek)
+ a töréspont valószinüleg 65 és 70 között van, meg kellene keresni - Igen, a 67 az első ami nem 1 node-ot vizsgál és full enumerationnal fut 45 percig
+ a Rob által ajánlott cikkekben utánanézni a GS méreteknek és ha kell méréseket is végezni
+ migrálni a polytópszámolót és unit tesztet irni hozzá (vincivel generálni tesztértékeket)
+ megirni a bounding function keresőket, paraméter az első gs vektor hossza (jegyzet, hermite faktorok a füzetben). - fölösleges, egyszerűbb, ha a paraméter a bázis 
+ pruning function-öket számolni (LLL-es bemenetet feltételezve) 5-ös lépésközzel 30 és 80 között, a többit meg approximálni (ahogy a bkz 2.0-ás cikk is irja) - nem lehet a bázis ismerete nélkül
+ kitenni a bounding function keresőt egy külön alkalmazásba
- lattice I/O-t implementálni és letisztázni a bounding function kereső alkalmazást
	- expected running time és success probability-t commentben beleirni
+ kideriteni, hogy miért lesz a mu mátrixom első sora nulla és miért nem lesz bázismátrix első sora nulla
	+ Válasz: az NTL kispórolja a mu főátlójából az 1-eseket
+ kideriteni, hogy miért n-1 hosszú a legrövidebb vektor és nem n/2 
	+ Válasz: mert egyrészt független a hossz a megoldásban lévő egyesek számától, másrészt meg valóban igy jön ki a skálázás után (itt vektorokat skálázunk ez teljesen másképp viselkedik mint a térfogat. Tényleg kijön, számitás a füzetben.
- kideriteni, hogy mi a baj a bounding function keresővel
	- miért lesz az első vágás olyan magas? (gyanús, hogy a polytópszámolóban van elrontva a legalacsonyabb dimenzió)
	- miért megy cikkcakban ha sokáig futtatom?
- megirni a bounding function kereső unit tesztjeit
- Megnézni, hogy milyen hatással van a mu korrigálása az enumerationra 
	- valszeg semmilyen, mert a főátlót eleve 1-nek veszi. Megkeresni a vonatkozó részt az algoritmusban
- tesztadatokat generálni majd tesztelni a bounding function-t (BKZ 30 vagy 35, dimenzió 80)
- a cjlossos tesztprogramból automatikus tesztet irni,  
- Megirni a pruningos BKZ-t, enumerationt külön függvénybe tenni
- Minden enumeration hivást és a vonatkozó unit teszteket átirni az új enumeration-re 
- kikisérletezni a paramétereket a bkz automatikus bounding function keresőjéhez
- Implementálni a radius reductiont és az early terminationt 
- Implementálni az unexpected early terminationt (mindig kiirja lemezre, hogy hanyadik iterációnál jár és hogy mi az aktuális bázis)
- refaktorálni a toolok paraméterfeldolgozását
******** Itt lesz kész a BKZ1.5 **********
- a rekurzive hivás paramétereit kikisérletezni :
	- Hermite faktorokat lemérni (early terminatiönnel és anélkül)
	- várható futási időket a bounding function számolóval összevetni
- random lattice-ekre is elvégezni a méréseket és összehasonlitani a cjlossosokkal (ehhez előtte megnézni Gama-Nguyent)
- saját namespace-t csinálni hasonlón dinamikusan mint az NTL-ben
- polytopvol unit tesztet kiegésziteni 15 dimenzióra
- megirni a cikket és a megjelenés után átirni a dokumentációban a hivatkozásokat amiket lehet a saját cikkemre
- Általános BKZ-t implementálni: LLL -el redukálni bkz helyett és úgy lemérni az időket (10000000 node kell a viszonylagos stabilitáshoz és 45-nél már elég gyakran nem éri ezt el, szóval az az eredmény nem lesz olyan pontos)
	+ paraméterezni a programot a sample mérettel (hogy tudjam becsülni a magas mintás futási időt alacsony mintamérettel), futási időket megbecsülni
	- 50 dimenzióval kikisérletezni a sample méretet ami kell a 3 stabil tizedesjegyhez
	- lemérni 50, 55, 60, 65, 70, 75, 80 -ra  (automatizálva)
	- extrapolálni 40, 45 -re (automatizálni) 
- Általános bounding function-öket találni (erősen opcionális: lehet róla irni, de kicsi a siker valószinűsége és nem egy nagy eredmény)
	- GSA feltételes bounding function keresőt implementálni
	- tesztelni, hogy hogyan változik a bounding function a gs hossz változtatásával
	- tesztelni, hogy hogyan változik a futási idők változtatásával

Problémák:
- az NTL szabványos függvényeit használva külön kell kiszámolni a GS együtthatókat, pedig azokat már a redukcióhoz kiszámolja. Lehetséges megoldások:
	- igy hagyni és a számitásokat úgy végezni mintha nem lenne ott (ugyanis magas dimenziókban tényleg elhanyagolható a költsége)
	- duplikálni és módositani a szükséges NTL függvényeket
- a cjloss bázisát publikussá kellett tennem, hogy működjenek a dolgok, lehet, hogy át kéne szerveznem, hogy a bázis ne csak adattag legyen, hanem a mat_ZZ kiterjesztése - vagy nem: az egész csak egy teszt, nem is kell a libbe, át fogom tenni a tests könyvtárba
- a méréshez egyéb utasitásokat is bele kell tennem az algoritmusba. Ez  tényleges futás esetén lassithatja és olyan paramétereket is megkövetel, amik egy sima enumeration hiváskor nem kellenek. Lehetőségek
	- bevállalom az ezzel járó lassulást (mennyivel is lesz ettől lassabb? (méréshez rögziteni a cjloss seedet))
	- duplikálom a kódot 
- alacsony dimenzióban többnyire csak nagyon kevés node-ot kell megvizsgálnia, igy olyan kevés időt tölt vele, hogy nem tudja mérni. Lehetséges megoldások:
	- ha megtalálta a legrövidebb vektort akkor resetelem és futtatom amig elég idő nem lesz -nagyon torzit
	- magasabb dimenziós mérésekből approximálom 
- bármilyen dimenzióban változó és bázistól függő a futási idő, kérdés, hogy hogyan rendeljek egy adott dimenzióhoz egy konkrét értéket. Tapasztalati várható érték (átlag tűnik a legjobbnak), de kérdés, 
		- hogy mennyi mintát vegyek alapul
		- milyen (cjloss vagy teljesen random) lattice-t vegyek alapul (majdnem mindegy, mert az LLL redukció úgyis hasonló formára hozza)
- eddig b_0^* hosszát használtam kezdő sugárnak. Mi az amit a BKZ használ és mi az amit Phong használt a BKZ 2.0-ában? A méréseknek is úgy lenne értelme, ha onnan inditanám (és akkor a kicsik is lehet hogy végigmennek)
